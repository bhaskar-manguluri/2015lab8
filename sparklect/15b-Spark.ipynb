{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns # ipython widgets are experimental\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Table of Contents\n",
    "* [SPARK](#SPARK)\n",
    "* [Spark Context](#Spark-Context)\n",
    "\t* &nbsp;\n",
    "\t\t* [Create A RDD](#Create-A-RDD)\n",
    "\t\t* [Call `collect` on an RDD: Lazy Spark](#Call-collect-on-an-RDD:-Lazy-Spark)\n",
    "\t\t* [Operations on RDDs](#Operations-on-RDDs)\n",
    "\t\t* [Word Examples](#Word-Examples)\n",
    "\t\t* [Key Value Pairs](#Key-Value-Pairs)\n",
    "\t\t* [word count 1](#word-count-1)\n",
    "\t\t* [word count 2:  `reduceByKey()`](#word-count-2:--reduceByKey%28%29)\n",
    "\t\t* [Nested Syntax](#Nested-Syntax)\n",
    "\t\t* [Using Cache](#Using-Cache)\n",
    "\t\t* [Fun with words](#Fun-with-words)\n",
    "\t\t* [DataFrames](#DataFrames)\n",
    "\t\t* [Machine Learning](#Machine-Learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With shameless stealing of some code and text from:\n",
    "\n",
    "- https://github.com/tdhopper/rta-pyspark-presentation/blob/master/slides.ipynb\n",
    "- Databricks and Berkeley Spark MOOC: https://www.edx.org/course/introduction-big-data-apache-spark-uc-berkeleyx-cs100-1x\n",
    "\n",
    "which you should go check out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing (Py)Spark locally\n",
    "For Mac users using Homebrew:\n",
    "\n",
    "```\n",
    "$ brew install apache-spark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Java SDK\n",
    "\n",
    "OR: Use the Vagrant based solution which will be talked about in the lab.\n",
    "\n",
    "```\n",
    "$ IPYTHON=1 pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ $ IPYTHON_OPTS=\"notebook --matplotlib inline\" pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "âžœ  ~  /anaconda/bin/pip install findspark\n",
    "You are using pip version 7.0.3, however version 7.1.2 is available.\n",
    "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
    "Collecting findspark\n",
    "  Downloading findspark-0.0.5-py2.py3-none-any.whl\n",
    "Installing collected packages: findspark\n",
    "Successfully installed findspark-0.0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Spark Context\n",
    "\n",
    "You can also use it directly from the notebook interface on the mac if you installed `apache-spark` using `brew` and also installed `findspark` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext() #creates singleton sparkContest => error if this is run again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also output's a bunch of stuff on my terminal. This is because the entire java context is started up.\n",
    "\n",
    "```Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
    "15/10/21 14:46:15 INFO SparkContext: Running Spark version 1.4.0\n",
    "2015-10-21 14:46:15.774 java[30685:c003] Unable to load realm info from SCDynamicStore\n",
    "15/10/21 14:46:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "15/10/21 14:46:15 INFO SecurityManager: Changing view acls to: rahul\n",
    "15/10/21 14:46:15 INFO SecurityManager: Changing modify acls to: rahul\n",
    "15/10/21 14:46:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(rahul); users with modify permissions: Set(rahul)\n",
    "15/10/21 14:46:16 INFO Slf4jLogger: Slf4jLogger started\n",
    "15/10/21 14:46:16 INFO Remoting: Starting remoting\n",
    "15/10/21 14:46:16 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.251.101.163:64359]\n",
    "15/10/21 14:46:16 INFO Utils: Successfully started service 'sparkDriver' on port 64359.\n",
    "15/10/21 14:46:16 INFO SparkEnv: Registering MapOutputTracker\n",
    "15/10/21 14:46:16 INFO SparkEnv: Registering BlockManagerMaster\n",
    "15/10/21 14:46:16 INFO DiskBlockManager: Created local directory at /private/var/folders/_f/y76rs29s3c57ykwyz9c8z12c0000gn/T/spark-00a4e09e-e5db-485f-81dc-2e5016e9a27e/blockmgr-8966e07c-223b-4c38-9273-11543aa9d3c1\n",
    "15/10/21 14:46:16 INFO MemoryStore: MemoryStore started with capacity 273.0 MB\n",
    "15/10/21 14:46:16 INFO HttpFileServer: HTTP File server directory is /private/var/folders/_f/y76rs29s3c57ykwyz9c8z12c0000gn/T/spark-00a4e09e-e5db-485f-81dc-2e5016e9a27e/httpd-6af0a9e0-1cfe-42c4-a1bd-e01715b98436\n",
    "15/10/21 14:46:16 INFO HttpServer: Starting HTTP Server\n",
    "15/10/21 14:46:17 INFO Utils: Successfully started service 'HTTP file server' on port 64360.\n",
    "15/10/21 14:46:17 INFO SparkEnv: Registering OutputCommitCoordinator\n",
    "15/10/21 14:46:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
    "15/10/21 14:46:18 INFO SparkUI: Started SparkUI at http://10.251.101.163:4040\n",
    "15/10/21 14:46:18 INFO Executor: Starting executor ID driver on host localhost\n",
    "15/10/21 14:46:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64361.\n",
    "15/10/21 14:46:18 INFO NettyBlockTransferService: Server created on 64361\n",
    "15/10/21 14:46:18 INFO BlockManagerMaster: Trying to register BlockManager\n",
    "15/10/21 14:46:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64361 with 273.0 MB RAM, BlockManagerId(driver, localhost, 64361)\n",
    "15/10/21 14:46:18 INFO BlockManagerMaster: Registered BlockManager\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f89a4452590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).map(lambda x: x**2).reduce(lambda x,y :x+y)\n",
    "# same as sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).map(lambda x: x**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 6], [16, 8], [25, 10], [36, 12], [49, 14], [64, 16], [81, 18], [100, 20]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).map(lambda x: [x**2,x*2]).filter(lambda x:x[1] < x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 9), (1, 7), (3, 16)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([(1,4),(2,9),(3,16),(1,3)]).reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4, 4, 9, 6, 16, 8, 25, 10, 36, 12, 49, 14, 64, 16, 81, 18, 100, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).map(lambda x: (x**2,x*2)).reduce(lambda x,y:x+y)\n",
    "#note that x,y and x+y(output) of reduce function are the same, that is a property of reduce function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create A RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "# Print out the type of wordsRDD\n",
    "print(type(wordsRDD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Call `collect` on an RDD: Lazy Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is lazy. Until you `collect`(or any other action), nothing is actually run.\n",
    "\n",
    ">Instead, they just remember the transformations applied to some base dataset (e.g. a file). The transformations are only computed when an action requires a result to be returned to the driver program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'elephant', 'rat', 'rat', 'cat']\n"
     ]
    }
   ],
   "source": [
    "print(wordsRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "15/10/21 14:59:59 INFO SparkContext: Starting job: collect at <ipython-input-6-dee494da0714>:1\n",
    "15/10/21 14:59:59 INFO DAGScheduler: Got job 0 (collect at <ipython-input-6-dee494da0714>:1) with 4 output partitions (allowLocal=false)\n",
    "15/10/21 14:59:59 INFO DAGScheduler: Final stage: ResultStage 0(collect at <ipython-input-6-dee494da0714>:1)\n",
    "15/10/21 14:59:59 INFO DAGScheduler: Parents of final stage: List()\n",
    "15/10/21 14:59:59 INFO DAGScheduler: Missing parents: List()\n",
    "15/10/21 14:59:59 INFO DAGScheduler: Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:396), which has no missing parents\n",
    "15/10/21 15:00:00 INFO MemoryStore: ensureFreeSpace(1224) called with curMem=0, maxMem=286300569\n",
    "15/10/21 15:00:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1224.0 B, free 273.0 MB)\n",
    "15/10/21 15:00:00 INFO MemoryStore: ensureFreeSpace(777) called with curMem=1224, maxMem=286300569\n",
    "15/10/21 15:00:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 777.0 B, free 273.0 MB)\n",
    "15/10/21 15:00:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64361 (size: 777.0 B, free: 273.0 MB)\n",
    "15/10/21 15:00:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:874\n",
    "15/10/21 15:00:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:396)\n",
    "15/10/21 15:00:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1379 bytes)\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 1384 bytes)\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 1379 bytes)\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 1403 bytes)\n",
    "15/10/21 15:00:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
    "15/10/21 15:00:00 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)\n",
    "15/10/21 15:00:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
    "15/10/21 15:00:00 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)\n",
    "15/10/21 15:00:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 646 bytes result sent to driver\n",
    "15/10/21 15:00:00 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 665 bytes result sent to driver\n",
    "15/10/21 15:00:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 641 bytes result sent to driver\n",
    "15/10/21 15:00:00 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 641 bytes result sent to driver\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 61 ms on localhost (1/4)\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 60 ms on localhost (2/4)\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 96 ms on localhost (3/4)\n",
    "15/10/21 15:00:00 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 63 ms on localhost (4/4)\n",
    "15/10/21 15:00:00 INFO DAGScheduler: ResultStage 0 (collect at <ipython-input-6-dee494da0714>:1) finished in 0.120 s\n",
    "15/10/21 15:00:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool\n",
    "15/10/21 15:00:00 INFO DAGScheduler: Job 0 finished: collect at <ipython-input-6-dee494da0714>:1, took 0.872367 s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Operations on RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Spark Programming Guide:\n",
    "\n",
    ">RDDs support two types of operations: transformations, which create a new dataset from an existing one, and actions, which return a value to the driver program after running a computation on the dataset. For example, map is a transformation that passes each dataset element through a function and returns a new RDD representing the results. On the other hand, reduce is an action that aggregates all the elements of the RDD using some function and returns the final result to the driver program (although there is also a parallel reduceByKey that returns a distributed dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Word Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n"
     ]
    }
   ],
   "source": [
    "def makePlural(word):\n",
    "    return word + 's'\n",
    "\n",
    "print makePlural('cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform one RDD into another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n",
      "['cats', 'elephants']\n"
     ]
    }
   ],
   "source": [
    "pluralRDD = wordsRDD.map(makePlural)\n",
    "print pluralRDD.first()\n",
    "print pluralRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluralRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'elephants', 'rats', 'rats', 'cats']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluralRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key Value Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]\n"
     ]
    }
   ],
   "source": [
    "wordPairs = wordsRDD.map(lambda w: (w, 1))\n",
    "print wordPairs.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### WORD COUNT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1), ('rat', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rat', 3), ('elephant', 1), ('cat', 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat','rat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "\n",
    "wordCounts = wordsRDD.map(lambda w: (w, 1))\n",
    "#.reduce(lambda x:len(x)) # reduce take two args of same type and outputs result of same type\n",
    "print wordCounts.collect()\n",
    "wordCounts.reduceByKey(lambda x,y:x+y).collect()\n",
    "#(wordsRDD.map(lambda word:(word,1)).reduce(lambda x,y:x+y))\n",
    "# if we use reduce instead of reduce by key , it gives this('cat',1)+('rat',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 64), (2, 8), (4, 16), (6, 72), (1, 2), (3, 9), (5, 25), (7, 49)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7,8,1,2,6]\n",
    "xrdd = sc.parallelize(x)\n",
    "(xrdd.map(lambda x:(x,x**2)).reduceByKey(lambda x,y:x+y).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Tons of shuffling](https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/images/reduce_by.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rat', 3), ('elephant', 1), ('cat', 2)]\n",
      "[('rat', [1, 1, 1]), ('elephant', [1]), ('cat', [1, 1])]\n"
     ]
    }
   ],
   "source": [
    "# this will print the same as above but uses groupBYKey and mapVlues instead of reduceByKey\n",
    "wordCountsCollected = (wordsRDD\n",
    "                       .map(lambda w: (w, 1))\n",
    "                       .groupByKey()\n",
    "                       .mapValues(lambda x: sum(x))\n",
    "                       .collect())\n",
    "print wordCountsCollected\n",
    "#useful to do transform into list of values as \n",
    "wordCountsCollected = (wordsRDD\n",
    "                       .map(lambda w: (w, 1))\n",
    "                       .groupByKey()\n",
    "                       .mapValues(lambda x: list(x))\n",
    "                       .collect())\n",
    "print wordCountsCollected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4) PythonRDD[48] at RDD at PythonRDD.scala:43 []\n",
      " |  MapPartitionsRDD[47] at mapPartitions at PythonRDD.scala:346 []\n",
      " |  ShuffledRDD[46] at partitionBy at NativeMethodAccessorImpl.java:-2 []\n",
      " +-(4) PairwiseRDD[45] at reduceByKey at <ipython-input-19-c1214cba7909>:3 []\n",
      "    |  PythonRDD[44] at reduceByKey at <ipython-input-19-c1214cba7909>:3 []\n",
      "    |  ParallelCollectionRDD[21] at parallelize at PythonRDD.scala:396 []\n"
     ]
    }
   ],
   "source": [
    "print (wordsRDD\n",
    "    .map(lambda w: (w, 1))\n",
    "    .reduceByKey(lambda x,y: x+y)).toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[57] at textFile at NativeMethodAccessorImpl.java:-2\n",
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.textFile('../wordcount/green_eggs_n_ham.txt')\n",
    "#wordsRDD = sc.parallelize(wordsList, 4)\n",
    "print wordsRDD\n",
    "wordsRDD.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 105 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#this is rerun from the start\n",
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 6.56 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[50] at textFile at NativeMethodAccessorImpl.java:-2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#default storage level (MEMORY_ONLY)\n",
    "wordsRDD.cache()#nothing done this is still lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 8 ms, total: 8 ms\n",
      "Wall time: 165 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#parallelize is rerun and cached because we told it to cache\n",
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 93.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#this `sc.textFile` is not rerun in this case\n",
    "wordsRDD.count()\n",
    "# replace words RDD with something other than wordslist, like a book\n",
    "#hoping clocked time differences  will be more clear in distributed system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is this useful: it is when you have branching parts or loops, so that you dont do things again and again. Spark, being \"lazy\" will rerun the chain again. So `cache` or `persist` serves as a checkpoint, breaking the RDD chain or the *lineage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 'mammal',\n",
       " 'elephant': 'mammal',\n",
       " 'heron': 'bird',\n",
       " 'owl': 'bird',\n",
       " 'rat': 'mammal'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birdsList=['heron','owl']\n",
    "animList=wordsList+birdsList\n",
    "animaldict={}\n",
    "for e in wordsList:\n",
    "    animaldict[e]='mammal'\n",
    "for e in birdsList:\n",
    "    animaldict[e]='bird'\n",
    "animaldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n"
     ]
    }
   ],
   "source": [
    "animsrdd = sc.parallelize(animList, 4)\n",
    "animsrdd.cache()\n",
    "#below runs the whole chain but causes cache to be populated\n",
    "mammalcount=animsrdd.filter(lambda w: animaldict[w]=='mammal').count()\n",
    "#now only the filter is carried out\n",
    "birdcount=animsrdd.filter(lambda w: animaldict[w]=='bird').count()\n",
    "print mammalcount, birdcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun with words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read http://spark.apache.org/docs/latest/programming-guide.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords=[e.strip() for e in open(\"english.stop.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3094"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juliusrdd=sc.textFile(\"./shakes/juliuscaesar.txt\")\n",
    "juliusrdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flat map is like map but outputs more than one value => flattens out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'1599'], [u'THE', u'TRAGEDY', u'OF', u'JULIUS', u'CAESAR'], [], [u'by', u'William', u'Shakespeare'], []]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21245"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print juliusrdd.map(lambda line: line.split()).take(5) #3094 split() => lines into comma seperated lists\n",
    "juliusrdd.flatMap(lambda line:line.split()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1599', u'THE', u'TRAGEDY', u'OF', u'JULIUS']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juliusrdd.flatMap(lambda line:line.split()).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'1599'],\n",
       " [u'THE', u'TRAGEDY', u'OF', u'JULIUS', u'CAESAR'],\n",
       " [],\n",
       " [u'BY', u'WILLIAM', u'SHAKESPEARE'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [u'DRAMATIS', u'PERSONAE'],\n",
       " [],\n",
       " [u'JULIUS', u'CAESAR,', u'ROMAN', u'STATESMAN', u'AND', u'GENERAL'],\n",
       " [u'OCTAVIUS,',\n",
       "  u'TRIUMVIR',\n",
       "  u'AFTER',\n",
       "  u\"CAESAR'S\",\n",
       "  u'DEATH,',\n",
       "  u'LATER',\n",
       "  u'AUGUSTUS',\n",
       "  u'CAESAR,'],\n",
       " [u'FIRST', u'EMPEROR', u'OF', u'ROME'],\n",
       " [u'MARK',\n",
       "  u'ANTONY,',\n",
       "  u'GENERAL',\n",
       "  u'AND',\n",
       "  u'FRIEND',\n",
       "  u'OF',\n",
       "  u'CAESAR,',\n",
       "  u'A',\n",
       "  u'TRIUMVIR',\n",
       "  u'AFTER',\n",
       "  u'HIS'],\n",
       " [u'DEATH'],\n",
       " [u'LEPIDUS,', u'THIRD', u'MEMBER', u'OF', u'THE', u'TRIUMVIRATE'],\n",
       " [u'MARCUS',\n",
       "  u'BRUTUS,',\n",
       "  u'LEADER',\n",
       "  u'OF',\n",
       "  u'THE',\n",
       "  u'CONSPIRACY',\n",
       "  u'AGAINST',\n",
       "  u'CAESAR'],\n",
       " [u'CASSIUS,', u'INSTIGATOR', u'OF', u'THE', u'CONSPIRACY'],\n",
       " [u'CASCA,', u'CONSPIRATOR', u'AGAINST', u'CAESAR'],\n",
       " [u'TREBONIUS,', u'\"', u'\"', u'\"'],\n",
       " [u'CAIUS', u'LIGARIUS,', u'\"', u'\"', u'\"']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.map(lambda line: line.split())\n",
    " .map(lambda line: [e.strip().upper() for e in line])\n",
    "  .take(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1599',\n",
       " u'THE',\n",
       " u'TRAGEDY',\n",
       " u'OF',\n",
       " u'JULIUS',\n",
       " u'CAESAR',\n",
       " u'BY',\n",
       " u'WILLIAM',\n",
       " u'SHAKESPEARE',\n",
       " u'DRAMATIS',\n",
       " u'PERSONAE',\n",
       " u'JULIUS',\n",
       " u'CAESAR,',\n",
       " u'ROMAN',\n",
       " u'STATESMAN',\n",
       " u'AND',\n",
       " u'GENERAL',\n",
       " u'OCTAVIUS,',\n",
       " u'TRIUMVIR',\n",
       " u'AFTER']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(juliusrdd.flatMap(lambda line:line.split()).map(lambda word:word.strip().upper()).count()) #21245\n",
    "(juliusrdd.flatMap(lambda line:line.split()).map(lambda word:word.strip().upper()).take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10511"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1599', 1),\n",
       " (u'tragedy', 1),\n",
       " (u'julius', 1),\n",
       " (u'caesar', 1),\n",
       " (u'william', 1),\n",
       " (u'shakespeare', 1),\n",
       " (u'dramatis', 1),\n",
       " (u'personae', 1),\n",
       " (u'julius', 1),\n",
       " (u'caesar,', 1),\n",
       " (u'roman', 1),\n",
       " (u'statesman', 1),\n",
       " (u'general', 1),\n",
       " (u'octavius,', 1),\n",
       " (u'triumvir', 1),\n",
       " (u\"caesar's\", 1),\n",
       " (u'death,', 1),\n",
       " (u'augustus', 1),\n",
       " (u'caesar,', 1),\n",
       " (u'emperor', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .take(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', 2),\n",
       " (u'pardon', 5),\n",
       " (u'shouted.', 1),\n",
       " (u'foul', 1),\n",
       " (u'cause;', 1),\n",
       " (u'cognizance.', 1),\n",
       " (u'sleep', 6),\n",
       " (u'abide', 2),\n",
       " (u\"friend's\", 1),\n",
       " (u'muffling', 1),\n",
       " (u'hate', 1),\n",
       " (u'up.', 3),\n",
       " (u'up,', 3),\n",
       " (u'pardon!', 1),\n",
       " (u'venom', 1),\n",
       " (u'presents', 1),\n",
       " (u'whatsoever', 1),\n",
       " (u'sway', 1),\n",
       " (u'hats', 1),\n",
       " (u'reveler!', 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .take(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'brutus.', 211),\n",
       " (u'cassius.', 152),\n",
       " (u'thou', 107),\n",
       " (u'caesar', 96),\n",
       " (u'brutus', 75),\n",
       " (u'antony.', 73),\n",
       " (u'citizen.', 68),\n",
       " (u'good', 66),\n",
       " (u'caesar.', 62),\n",
       " (u'thy', 54),\n",
       " (u'brutus,', 54),\n",
       " (u'caesar,', 46),\n",
       " (u'casca.', 44),\n",
       " (u'\"', 44),\n",
       " (u'men', 41),\n",
       " (u'you,', 41),\n",
       " (u'enter', 40),\n",
       " (u\"caesar's\", 40),\n",
       " (u'lucius.', 38),\n",
       " (u'cassius,', 38)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .takeOrdered(20, lambda x: -x[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(211, u'brutus.'),\n",
       " (152, u'cassius.'),\n",
       " (107, u'thou'),\n",
       " (96, u'caesar'),\n",
       " (75, u'brutus')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ismormorphically\n",
    "(juliusrdd.flatMap(lambda line:line.split())\n",
    " .map(lambda word:word.lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word:(word,1))\n",
    " .reduceByKey(lambda a,b:a+b)\n",
    " .map(lambda (a,b):(b,a))\n",
    " .top(5)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'brutus.', u'cassius.', u'thou', u'caesar', u'brutus', u'antony.', u'citizen.', u'good', u'caesar.', u'thy', u'brutus,', u'caesar,', u'casca.', u'\"', u'men', u'you,', u'enter', u\"caesar's\", u'lucius.', u'cassius,')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAF1CAYAAADWVvIhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f897ba3ad90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "captions, counts=zip(*juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .takeOrdered(20, lambda x: -x[1])\n",
    ")\n",
    "print captions\n",
    "pos = np.arange(len(counts))\n",
    "plt.bar(pos, counts);\n",
    "plt.xticks(pos+0.4, captions, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shakesrdd=sc.textFile(\"shakes/juliuscaesar.txt\", minPartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1599',\n",
       " u'THE TRAGEDY OF JULIUS CAESAR',\n",
       " u'',\n",
       " u'by William Shakespeare',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'Dramatis Personae',\n",
       " u'',\n",
       " u'  JULIUS CAESAR, Roman statesman and general']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakesrdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(211, u'brutus.'),\n",
       " (152, u'cassius.'),\n",
       " (107, u'thou'),\n",
       " (96, u'caesar'),\n",
       " (75, u'brutus'),\n",
       " (73, u'antony.'),\n",
       " (68, u'citizen.'),\n",
       " (66, u'good'),\n",
       " (62, u'caesar.'),\n",
       " (54, u'brutus,'),\n",
       " (54, u'thy'),\n",
       " (46, u'caesar,'),\n",
       " (44, u'casca.'),\n",
       " (44, u'\"'),\n",
       " (41, u'men'),\n",
       " (41, u'you,'),\n",
       " (40, u'enter'),\n",
       " (40, u\"caesar's\"),\n",
       " (38, u'cassius,'),\n",
       " (38, u'lucius.'),\n",
       " (36, u'man'),\n",
       " (35, u'hath'),\n",
       " (35, u'noble'),\n",
       " (34, u'give'),\n",
       " (33, u'hear'),\n",
       " (33, u'me,'),\n",
       " (33, u'mark'),\n",
       " (32, u'thee'),\n",
       " (32, u'messala.'),\n",
       " (30, u'him.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(shakesrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .map(lambda (x,y): (y,x))\n",
    " .sortByKey(0,1)\n",
    " .take(30)\n",
    ")\n",
    "# add trimming the punctutations from words, => 'brutus' = 'brutus.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SparkContext.wholeTextFile`...\n",
    "\n",
    ">lets you read a directory containing multiple small text files, and returns each of them as (filename, content) pairs. This is in contrast withÂ textFile, which would return one record per line in each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From http://www.stat.berkeley.edu/scf/paciorek-spark-2014.html:\n",
    "\n",
    ">You want each partition to be able to fit in the memory availalbe on a node, and if you have multi-core nodes, you want that as many partitions as there are cores be able to fit in memory.\n",
    "\n",
    ">For load-balancing you'll want at least as many partitions as total computational cores in your cluster and probably rather more partitions. The Spark documentation suggests 2-4 partitions (which they also seem to call slices) per CPU. Often there are 100-10,000 partitions. Another rule of thumb is that tasks should take at least 100 ms. If less than that, you may want to repartition to have fewer partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Spark DataFrame to Pandas\n",
    "\n",
    "`pandas_df = spark_df.toPandas()`\n",
    "\n",
    "Create a Spark DataFrame from Pandas\n",
    "\n",
    "`spark_df = context.createDataFrame(pandas_df)`\n",
    "\n",
    "Must fit in memory.\n",
    "\n",
    "![](https://ogirardot.files.wordpress.com/2015/05/rdd-vs-dataframe.png?w=640&h=360)\n",
    "\n",
    "VERY IMPORTANT: DataFrames in Spark are like RDD in the sense that theyâ€™re an immutable data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>73.847017</td>\n",
       "      <td>241.893563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>68.781904</td>\n",
       "      <td>162.310473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>74.110105</td>\n",
       "      <td>212.740856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>71.730978</td>\n",
       "      <td>220.042470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>69.881796</td>\n",
       "      <td>206.349801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender     Height      Weight\n",
       "0   Male  73.847017  241.893563\n",
       "1   Male  68.781904  162.310473\n",
       "2   Male  74.110105  212.740856\n",
       "3   Male  71.730978  220.042470\n",
       "4   Male  69.881796  206.349801"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://dl.dropboxusercontent.com/u/75194/stats/data/01_heights_weights_genders.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'createDataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-8f640eb68630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msparkdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'createDataFrame'"
     ]
    }
   ],
   "source": [
    "sparkdf = sc.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Gender: string, Height: double, Weight: double]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)\n",
    "sparkdf = sqlsc.createDataFrame(df)\n",
    "sparkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+----------------+\n",
      "|Gender|           Height|          Weight|\n",
      "+------+-----------------+----------------+\n",
      "|  Male|  73.847017017515|241.893563180437|\n",
      "|  Male|68.78190404589029|  162.3104725213|\n",
      "|  Male|74.11010539178491|  212.7408555565|\n",
      "|  Male| 71.7309784033377|220.042470303077|\n",
      "|  Male| 69.8817958611153|206.349800623871|\n",
      "+------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sparkdf.Gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [73.8470170175,241.89356318]),\n",
       " LabeledPoint(1.0, [68.7819040459,162.310472521]),\n",
       " LabeledPoint(1.0, [74.1101053918,212.740855557]),\n",
       " LabeledPoint(1.0, [71.7309784033,220.042470303]),\n",
       " LabeledPoint(1.0, [69.8817958611,206.349800624])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "data=sparkdf.map(lambda row: LabeledPoint(row.Gender=='Male',[row.Height, row.Weight]))\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [73.8470170175,241.89356318]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [73.8470170175,241.89356318]),\n",
       " LabeledPoint(1.0, [68.7819040459,162.310472521]),\n",
       " LabeledPoint(1.0, [74.1101053918,212.740855557]),\n",
       " LabeledPoint(1.0, [71.7309784033,220.042470303]),\n",
       " LabeledPoint(1.0, [69.8817958611,206.349800624])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=sparkdf.map(lambda row: LabeledPoint(row[0]=='Male',row[1:]))\n",
    "print data2.take(1)[0].label, data2.take(1)[0].features\n",
    "data2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[131] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = data.randomSplit([0.7,0.3])\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.255629122111,0.105249071938]\n"
     ]
    }
   ],
   "source": [
    "print model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "results = test.map(lambda lp: (lp.label, float(model.predict(lp.features))))\n",
    "print results.take(10)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9196031474512487"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy=results.filter(lambda (a,p): a==p).count()/float(results.count())\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.evaluation.BinaryClassificationMetrics'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9196027116358766"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(metrics)\n",
    "metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.mllib.classification.LogisticRegressionModel"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf mylogistic.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(sc, \"mylogistic.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline API automates a lot of this stuff, allowing us to work directly on dataframes. It is not all supported in Python, as yet. More of it in the HW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also see:\n",
    "\n",
    "- http://jordicasanellas.weebly.com/data-science-blog/machine-learning-with-spark\n",
    "- http://spark.apache.org/docs/latest/mllib-guide.html\n",
    "- http://www.techpoweredmath.com/spark-dataframes-mllib-tutorial/\n",
    "- http://spark.apache.org/docs/latest/api/python/\n",
    "- http://spark.apache.org/docs/latest/programming-guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rdd.saveAsTextFile()`Â saves an RDD as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
